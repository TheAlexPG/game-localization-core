import os
import re
import time
import json
from pathlib import Path
from typing import List, Dict, Tuple
from openai import OpenAI
from dotenv import load_dotenv
load_dotenv()

# ===== –ù–ê–õ–ê–®–¢–£–í–ê–ù–ù–Ø =====
SOURCE_DIR = "./SILKSONG_EN/._Decrypted"  # –ü–∞–ø–∫–∞ –∑ –æ—Ä–∏–≥—ñ–Ω–∞–ª—å–Ω–∏–º–∏ —Ñ–∞–π–ª–∞–º–∏
OUTPUT_DIR = "./SILKSONG_UA"  # –ü–∞–ø–∫–∞ –¥–ª—è –ø–µ—Ä–µ–∫–ª–∞–¥–µ–Ω–∏—Ö —Ñ–∞–π–ª—ñ–≤
BATCH_SIZE = 5  # –ö—ñ–ª—å–∫—ñ—Å—Ç—å —Ä—è–¥–∫—ñ–≤ –¥–ª—è –ø–µ—Ä–µ–∫–ª–∞–¥—É –∑–∞ —Ä–∞–∑

# OpenAI –Ω–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
MODEL_NAME = "gpt-5"  # –∞–±–æ "gpt-3.5-turbo" –¥–ª—è –¥–µ—à–µ–≤—à–æ–≥–æ –≤–∞—Ä—ñ–∞–Ω—Ç—É
TEMPERATURE = 1  # –ù–∏–∑—å–∫–∞ –¥–ª—è –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç—ñ –ø–µ—Ä–µ–∫–ª–∞–¥—É
MAX_RETRIES = 3
RETRY_DELAY = 2

# –ì–ª–æ—Å–∞—Ä—ñ–π —Ç–µ—Ä–º—ñ–Ω—ñ–≤ —â–æ –Ω–µ –ø–µ—Ä–µ–∫–ª–∞–¥–∞—î–º–æ
PRESERVE_TERMS = [
    "Hornet", "Pharloom", "Silksong", "Citadel",
    "Garmond", "Lace", "Shakra", "Coral"
]

# –ì–ª–æ—Å–∞—Ä—ñ–π –¥–ª—è –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ–≥–æ –ø–µ—Ä–µ–∫–ª–∞–¥—É
GLOSSARY = {
    "Weaver": "–¢–∫–∞—á",
    "Needle": "–ì–æ–ª–∫–∞",
    "Thread": "–ù–∏—Ç–∫–∞",
    "Silk": "–®–æ–≤–∫",
    "Hunter": "–ú–∏—Å–ª–∏–≤–µ—Ü—å",
    "Knight": "–õ–∏—Ü–∞—Ä",
    "Crest": "–ì–µ—Ä–±",
    "Wilds": "–ü—É—Å—Ç–∫–∞",
    "Forge": "–ö—É–∑–Ω—è",
    "Peak": "–ü—ñ–∫",
    "Void": "–ü–æ—Ä–æ–∂–Ω–µ—á–∞",
    "Soul": "–î—É—à–∞",
    "Mask": "–ú–∞—Å–∫–∞",
    "Charm": "–û–±–µ—Ä—ñ–≥",
    "Spool": "–ö–æ—Ç—É—à–∫–∞",
    "Fragment": "–§—Ä–∞–≥–º–µ–Ω—Ç"
}


class SilksongOpenAITranslator:
    def __init__(self):
        self.client = OpenAI(api_key=OPENAI_API_KEY)
        self.translation_cache = {}
        self.stats = {"translated": 0, "cached": 0, "errors": 0, "tokens_used": 0}
        self.load_cache()

    def create_prompt(self, text: str) -> str:
        """–°—Ç–≤–æ—Ä—é—î –ø—Ä–æ–º–ø—Ç –¥–ª—è –ø–µ—Ä–µ–∫–ª–∞–¥—É –∑ —É—Ä–∞—Ö—É–≤–∞–Ω–Ω—è–º —Ç–µ–≥—ñ–≤ —Ç–∞ —Ñ–æ—Ä–º–∞—Ç—É–≤–∞–Ω–Ω—è"""
        glossary_str = "\n".join([f"- {en}: {ua}" for en, ua in GLOSSARY.items()])
        preserve_str = ", ".join(PRESERVE_TERMS)

        prompt = f"""You are an expert translator for the dark fantasy game "Hollow Knight: Silksong", translating from English to Ukrainian. Provide ONLY the Ukrainian translation of the text.

### CRITICAL RULES ###
1.  **Preserve ALL Tags and Formatting:** All special characters, line breaks (\\n), and tags like `<tag>`, `<|token|>` or `{{variable}}` MUST be preserved exactly as they are in the original text. DO NOT translate, change, or remove them.
2.  **Atmospheric Style:** Maintain the poetic, dark, and sometimes archaic style of the original game.
3.  **Glossary Adherence:** Strictly use the provided glossary for consistency.
{glossary_str}
4.  **Do Not Translate Names:** The following names must remain in English: {preserve_str}.

### EXAMPLE OF PRESERVING TAGS AND NEWLINES ###
- **Original Text:**
"Ah, <|hero_name|>. Your journey is long.\\nUse the {{item_bell}} to call for aid."
- **Correct Ukrainian Translation:**
"–ê—Ö, <|hero_name|>. –¢–≤–æ—è –ø–æ–¥–æ—Ä–æ–∂ –¥–æ–≤–≥–∞.\\n–í–∏–∫–æ—Ä–∏—Å—Ç–∞–π {{item_bell}}, —â–æ–± –ø–æ–∫–ª–∏–∫–∞—Ç–∏ –Ω–∞ –¥–æ–ø–æ–º–æ–≥—É."

### TEXT TO TRANSLATE ###
{text}

### UKRAINIAN TRANSLATION ###"""

        return prompt

    def call_openai(self, text: str) -> str:
        """–í–∏–∫–ª–∏–∫–∞—î OpenAI API –¥–ª—è –ø–µ—Ä–µ–∫–ª–∞–¥—É"""
        for attempt in range(MAX_RETRIES):
            try:
                response = self.client.chat.completions.create(
                    model=MODEL_NAME,
                    messages=[
                        {
                            "role": "system",
                            "content": "You are a professional Ukrainian game translator specializing in dark fantasy games. Translate accurately while preserving the atmospheric style and all formatting/tags."
                        },
                        {
                            "role": "user",
                            "content": self.create_prompt(text)
                        }
                    ],
                    temperature=TEMPERATURE,
                    max_completion_tokens=30000
                )

                translation = response.choices[0].message.content.strip()

                # –û–Ω–æ–≤–ª—é—î–º–æ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É —Ç–æ–∫–µ–Ω—ñ–≤
                if hasattr(response, 'usage'):
                    self.stats["tokens_used"] += response.usage.total_tokens

                # –û—á–∏—â–∞—î–º–æ –≤—ñ–¥–ø–æ–≤—ñ–¥—å –≤—ñ–¥ –º–æ–∂–ª–∏–≤–∏—Ö –ø–æ—è—Å–Ω–µ–Ω—å
                if ":" in translation[:50]:  # –Ø–∫—â–æ —î –∑–∞–≥–æ–ª–æ–≤–æ–∫ —Ç–∏–ø—É "Translation:"
                    translation = translation.split(":", 1)[1].strip()

                return translation

            except Exception as e:
                print(f"  API error (attempt {attempt + 1}/{MAX_RETRIES}): {e}")

                if "rate_limit" in str(e).lower():
                    print(f"  Rate limit hit, waiting {RETRY_DELAY * 2} seconds...")
                    time.sleep(RETRY_DELAY * 2)
                elif "api_key" in str(e).lower():
                    print("‚ùå Invalid API key! Please check your OpenAI API key.")
                    exit(1)

                if attempt < MAX_RETRIES - 1:
                    time.sleep(RETRY_DELAY)

        self.stats["errors"] += 1
        return f"[TRANSLATION ERROR] {text}"

    def translate_text(self, text: str) -> str:
        """–ü–µ—Ä–µ–∫–ª–∞–¥–∞—î —Ç–µ–∫—Å—Ç –∑ –∫–µ—à—É–≤–∞–Ω–Ω—è–º"""
        # –ü—Ä–æ–ø—É—Å–∫–∞—î–º–æ —Ç–µ—Ö–Ω—ñ—á–Ω—ñ —Ä—è–¥–∫–∏
        if not text or text.startswith('$') or len(text) <= 2:
            return text

        # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ –∫–µ—à
        if text in self.translation_cache:
            self.stats["cached"] += 1
            return self.translation_cache[text]

        # –ü–µ—Ä–µ–∫–ª–∞–¥–∞—î–º–æ
        print(f"  Translating: {text[:50]}...")
        translation = self.call_openai(text)

        # –ó–±–µ—Ä—ñ–≥–∞—î–º–æ –≤ –∫–µ—à
        self.translation_cache[text] = translation
        self.stats["translated"] += 1

        # –ù–µ–≤–µ–ª–∏–∫–∞ –∑–∞—Ç—Ä–∏–º–∫–∞ —â–æ–± –Ω–µ –ø–µ—Ä–µ–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ API
        time.sleep(0.2)

        return translation

    def extract_entries(self, file_path: str) -> List[Tuple[str, str]]:
        """–í–∏—Ç—è–≥—É—î –≤—Å—ñ entry –∑ —Ñ–∞–π–ª—É"""
        entries = []

        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()

            # –®—É–∫–∞—î–º–æ entry —Ç–µ–≥–∏
            pattern = r'<entry name="([^"]+)">([^<]*)</entry>'
            matches = re.findall(pattern, content, re.DOTALL)

            return matches
        except Exception as e:
            print(f"Error reading {file_path}: {e}")
            return []

    def process_file(self, input_path: str, output_path: str):
        """–û–±—Ä–æ–±–ª—è—î –æ–¥–∏–Ω —Ñ–∞–π–ª –ª–æ–∫–∞–ª—ñ–∑–∞—Ü—ñ—ó"""
        print(f"\nüìÑ Processing: {Path(input_path).name}")

        with open(input_path, 'r', encoding='utf-8') as f:
            content = f.read()

        # –í–∏—Ç—è–≥—É—î–º–æ entries
        entries = self.extract_entries(input_path)

        if not entries:
            print("  No entries found, copying as is")
            os.makedirs(os.path.dirname(output_path), exist_ok=True)
            with open(output_path, 'w', encoding='utf-8') as f:
                f.write(content)
            return

        print(f"  Found {len(entries)} entries")

        # –ü–µ—Ä–µ–∫–ª–∞–¥–∞—î–º–æ
        translated_content = content
        for i, (name, text) in enumerate(entries):
            if i % 10 == 0 and i > 0:
                print(f"  Progress: {i}/{len(entries)}")
                # –ó–±–µ—Ä—ñ–≥–∞—î–º–æ –∫–µ—à –∫–æ–∂–Ω—ñ 10 –∑–∞–ø–∏—Å—ñ–≤
                self.save_cache()

            # –ü–µ—Ä–µ–∫–ª–∞–¥–∞—î–º–æ —Ç–µ–∫—Å—Ç
            translated = self.translate_text(text)

            # –ó–∞–º—ñ–Ω—é—î–º–æ –≤ –∫–æ–Ω—Ç–µ–Ω—Ç—ñ
            old_entry = f'<entry name="{name}">{text}</entry>'
            new_entry = f'<entry name="{name}">{translated}</entry>'
            translated_content = translated_content.replace(old_entry, new_entry)

        # –ó–±–µ—Ä—ñ–≥–∞—î–º–æ —Ñ–∞–π–ª
        os.makedirs(os.path.dirname(output_path), exist_ok=True)
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(translated_content)

        print(f"  ‚úÖ Saved to: {output_path}")

    def process_all_files(self):
        """–û–±—Ä–æ–±–ª—è—î –≤—Å—ñ —Ñ–∞–π–ª–∏"""
        source_path = Path(SOURCE_DIR)
        output_path = Path(OUTPUT_DIR)

        # –ó–Ω–∞—Ö–æ–¥–∏–º–æ —Ñ–∞–π–ª–∏
        files = list(source_path.glob("EN_*.txt")) + list(source_path.glob("EN_*.xml"))

        if not files:
            print("‚ùå No files found! Make sure SILKSONG_EN/._Decrypted folder contains decrypted files")
            return

        print(f"üéÆ SILKSONG UKRAINIAN TRANSLATION")
        print(f"üìÅ Found {len(files)} files to translate")
        print(f"ü§ñ Using model: {MODEL_NAME}")
        print(f"üîë API: OpenAI\n")

        # –û—Ü—ñ–Ω–∫–∞ –≤–∞—Ä—Ç–æ—Å—Ç—ñ
        estimated_cost = self.estimate_cost(files)
        print(f"üí∞ Estimated cost: ${estimated_cost:.2f} (approximate)")

        response = input("\n‚ö†Ô∏è  Continue with translation? (yes/no): ")
        if response.lower() not in ['yes', 'y']:
            print("Translation cancelled.")
            return

        # –û–±—Ä–æ–±–ª—è—î–º–æ —Ñ–∞–π–ª–∏
        for i, file_path in enumerate(files, 1):
            print(f"\n[{i}/{len(files)}]", end="")
            relative_path = file_path.relative_to(source_path)
            output_file = output_path / relative_path

            self.process_file(str(file_path), str(output_file))

            # –ó–±–µ—Ä—ñ–≥–∞—î–º–æ –ø—Ä–æ–≥—Ä–µ—Å
            self.save_cache()

        # –§—ñ–Ω–∞–ª—å–Ω–∞ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        print(f"\n{'=' * 50}")
        print(f"‚úÖ TRANSLATION COMPLETED!")
        print(f"üìä Statistics:")
        print(f"  - Translated: {self.stats['translated']} strings")
        print(f"  - From cache: {self.stats['cached']} strings")
        print(f"  - Errors: {self.stats['errors']} strings")
        print(f"  - Tokens used: {self.stats['tokens_used']:,}")

        # –†–æ–∑—Ä–∞—Ö—É–Ω–æ–∫ –≤–∞—Ä—Ç–æ—Å—Ç—ñ
        if MODEL_NAME == "gpt-4-turbo-preview":
            cost = (self.stats['tokens_used'] / 1000) * 0.01  # $0.01 per 1K tokens (approximate)
        else:  # gpt-3.5-turbo
            cost = (self.stats['tokens_used'] / 1000) * 0.0015  # $0.0015 per 1K tokens

        print(f"üíµ Approximate cost: ${cost:.2f}")
        print(f"üìÅ Output folder: {OUTPUT_DIR}")
        print(f"üíæ Cache saved to: translation_cache.json")

    def estimate_cost(self, files):
        """–û—Ü—ñ–Ω—é—î –ø—Ä–∏–±–ª–∏–∑–Ω—É –≤–∞—Ä—Ç—ñ—Å—Ç—å –ø–µ—Ä–µ–∫–ª–∞–¥—É"""
        total_chars = 0
        for file_path in files[:3]:  # –ë–µ—Ä–µ–º–æ –ø–µ—Ä—à—ñ 3 —Ñ–∞–π–ª–∏ –¥–ª—è –æ—Ü—ñ–Ω–∫–∏
            entries = self.extract_entries(str(file_path))
            for _, text in entries:
                total_chars += len(text)

        # –ï–∫—Å—Ç—Ä–∞–ø–æ–ª—é—î–º–æ –Ω–∞ –≤—Å—ñ —Ñ–∞–π–ª–∏
        avg_per_file = total_chars / min(3, len(files))
        total_estimated = avg_per_file * len(files)

        # –ü—Ä–∏–±–ª–∏–∑–Ω–æ 4 —Å–∏–º–≤–æ–ª–∏ = 1 —Ç–æ–∫–µ–Ω
        estimated_tokens = (total_estimated / 4) * 2  # x2 –¥–ª—è –∑–∞–ø–∏—Ç—É —ñ –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ

        if MODEL_NAME == "gpt-4-turbo-preview":
            return (estimated_tokens / 1000) * 0.01
        else:
            return (estimated_tokens / 1000) * 0.0015

    def save_cache(self):
        """–ó–±–µ—Ä—ñ–≥–∞—î –∫–µ—à –ø–µ—Ä–µ–∫–ª–∞–¥—ñ–≤"""
        with open("translation_cache.json", 'w', encoding='utf-8') as f:
            json.dump(self.translation_cache, f, ensure_ascii=False, indent=2)

    def load_cache(self):
        """–ó–∞–≤–∞–Ω—Ç–∞–∂—É—î –∫–µ—à –ø–µ—Ä–µ–∫–ª–∞–¥—ñ–≤"""
        try:
            with open("translation_cache.json", 'r', encoding='utf-8') as f:
                self.translation_cache = json.load(f)
                print(f"üìö Loaded {len(self.translation_cache)} cached translations")
        except FileNotFoundError:
            print("üìö Starting with empty translation cache")


def test_connection():
    """–¢–µ—Å—Ç—É—î –∑'—î–¥–Ω–∞–Ω–Ω—è –∑ OpenAI API"""
    print("üîç Testing OpenAI API connection...")

    try:
        client = OpenAI(api_key=OPENAI_API_KEY)
        response = client.chat.completions.create(
            model=MODEL_NAME,
            messages=[
                {"role": "user", "content": "Say 'Hello' in Ukrainian"}
            ]
        )

        result = response.choices[0].message.content
        print(f"‚úÖ Connection successful!")
        print(f"   Test response: {result}")
        return True

    except Exception as e:
        print(f"‚ùå Connection failed: {e}")
        return False


if __name__ == "__main__":
    print("üéÆ HOLLOW KNIGHT: SILKSONG - Ukrainian Translation Tool (OpenAI)")
    print("=" * 50)

    # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ API –∫–ª—é—á–∞
    if OPENAI_API_KEY == "YOUR_API_KEY_HERE":
        print("‚ùå Please set your OpenAI API key in the script!")
        print("   Edit the OPENAI_API_KEY variable")
        exit(1)

    # –¢–µ—Å—Ç—É—î–º–æ –∑'—î–¥–Ω–∞–Ω–Ω—è
    if not test_connection():
        print("\n‚ö†Ô∏è  Please check:")
        print("1. Your OpenAI API key is valid")
        print("2. You have credits in your OpenAI account")
        print("3. The model name is correct (gpt-4-turbo-preview or gpt-3.5-turbo)")
        exit(1)

    print("\n" + "=" * 50)

    # –ó–∞–ø—É—Å–∫–∞—î–º–æ –ø–µ—Ä–µ–∫–ª–∞–¥
    translator = SilksongOpenAITranslator()
    translator.process_all_files()

    print("\nüéâ Done! Now you can:")
    print("1. Check translations in SILKSONG_UA folder")
    print("2. Use 'SilksongDecryptor.exe -encrypt SILKSONG_UA' to encrypt back")
    print("3. Replace original files in the game")